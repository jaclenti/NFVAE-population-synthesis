{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"VveD05\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.6.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"VveD05\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"VveD05\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"jIeWSS\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.6.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"jIeWSS\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"jIeWSS\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "import jl_vae\n",
    "import jl_nflows_geo_coordinates_2 as nfg\n",
    "from jl_nflows_geo_coordinates import load_nf as load_dict\n",
    "import utils\n",
    "import config\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers_nf = 32\n",
    "hidden_features_nf = 32\n",
    "num_epochs_nf = 20000\n",
    "lr_nf_ = 10\n",
    "lr_nf = lr_nf_ / 1000000\n",
    "opt_nf = \"Adam\" \n",
    "flow_name = \"NSF_CL\"\n",
    "batch_dim_nf = 100\n",
    "_ = \"nf\"\n",
    "\n",
    "latent_dims_vae = 20\n",
    "epochs_vae = 100\n",
    "middle_hidden_dims_vae = [64, 32]\n",
    "lr_vae = 0.001\n",
    "opt_vae = \"Adam\"\n",
    "\n",
    "# geo_data_dict = jl_vae.load_geo_data()\n",
    "abm_path = \"ISP_data_for_ABM/ISP_ABM_up_to_2024_08_0001.csv\"\n",
    "data = pd.read_csv(jl_vae.path_intermediate + abm_path, index_col = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prov = \"BO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = \"250703\" + prov\n",
    "            \n",
    "path_nf = jl_vae.path_pop_synth + f\"nf_models/nf_{date}.pkl\"\n",
    "            \n",
    "df_prov_full = jl_vae.get_df_prov(prov, dropna = False)\n",
    "\n",
    "df_prov_full = df_prov_full[[u for u in jl_vae.cols if u not in [\"prov_abbrv\"]] + [\"x_norm\", \"y_norm\"]].assign(flag_air_conditioning_Missing = lambda x: x[\"flag_air_conditioning\"] == \"Missing\",\n",
    "                                                                                                               flag_multi_floor_Missing = lambda x: x[\"flag_multi_floor\"] == \"Missing\").replace(\"Missing\",0).astype(float)\n",
    "df_prov_dropna = jl_vae.get_df_prov(prov, dropna = True, drop_cols = [\"flag_air_conditioning\", \"flag_multi_floor\", 'floor_0.0', 'floor_1.0',\n",
    "                                                                      'floor_2.0', 'floor_3.0', 'floor_Missing', 'floor_plus_4'])\n",
    "\n",
    "\n",
    "\n",
    "model_settings = {\"num_layers_nf\": num_layers_nf, \"hidden_features_nf\": hidden_features_nf, \n",
    "                  \"num_epochs_nf\": num_epochs_nf, \"lr_nf\": lr_nf, \"opt_nf\": opt_nf, \"flow_name\": flow_name,\n",
    "                  \"batch_dim\": batch_dim_nf, \"date\": date, \"prov\": prov}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/housing/data/intermediate/jl_pop_synth/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jl_vae.path_pop_synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = df_prov_full.sample(frac = 0.95, random_state = 1111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 57/20001 [01:31<8:54:23,  1.61s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nf_dict \u001b[38;5;241m=\u001b[39m nfg\u001b[38;5;241m.\u001b[39mtrain_model(df_sample[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_norm\u001b[39m\u001b[38;5;124m\"\u001b[39m]], \n\u001b[1;32m      2\u001b[0m                           num_layers \u001b[38;5;241m=\u001b[39m num_layers_nf, \n\u001b[1;32m      3\u001b[0m                           hidden_features \u001b[38;5;241m=\u001b[39m hidden_features_nf,\n\u001b[1;32m      4\u001b[0m                           num_epochs \u001b[38;5;241m=\u001b[39m num_epochs_nf, \n\u001b[1;32m      5\u001b[0m                           opt_name \u001b[38;5;241m=\u001b[39m opt_nf, \n\u001b[1;32m      6\u001b[0m                           batch_dim \u001b[38;5;241m=\u001b[39m batch_dim_nf, \n\u001b[1;32m      7\u001b[0m                           flow_name \u001b[38;5;241m=\u001b[39m flow_name,\n\u001b[1;32m      8\u001b[0m                           hide_progress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, \n\u001b[1;32m      9\u001b[0m                           path \u001b[38;5;241m=\u001b[39m path_nf,\n\u001b[1;32m     10\u001b[0m                           model_settings \u001b[38;5;241m=\u001b[39m model_settings)\n",
      "File \u001b[0;32m~/housing-climate-main/notebooks/../src/jl_nflows_geo_coordinates_2.py:124\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(df, num_layers, hidden_features, lr, num_epochs, opt_name, flow_name, normalize_df, hide_progress, batch_dim, path, output, model_settings)\u001b[0m\n\u001b[1;32m    121\u001b[0m df_batch \u001b[38;5;241m=\u001b[39m df[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(low \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, high \u001b[38;5;241m=\u001b[39m n_obs, size \u001b[38;5;241m=\u001b[39m [batch_dim]), :]\n\u001b[1;32m    122\u001b[0m x_batch \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(df_batch)\n\u001b[0;32m--> 124\u001b[0m zs, prior_logprob, log_det \u001b[38;5;241m=\u001b[39m model(x_batch)\n\u001b[1;32m    125\u001b[0m logprob \u001b[38;5;241m=\u001b[39m prior_logprob \u001b[38;5;241m+\u001b[39m log_det\n\u001b[1;32m    126\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mtorch\u001b[38;5;241m.\u001b[39msum(logprob) \u001b[38;5;66;03m# NLL\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/housing-climate/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/housing-climate/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/housing-climate-main/notebooks/../src/pytorch-normalizing-flows/nflib/flows.py:283\u001b[0m, in \u001b[0;36mNormalizingFlowModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 283\u001b[0m     zs, log_det \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflow\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m    284\u001b[0m     prior_logprob \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprior\u001b[38;5;241m.\u001b[39mlog_prob(zs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m.\u001b[39mview(x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m zs, prior_logprob, log_det\n",
      "File \u001b[0;32m~/housing-climate-main/notebooks/../src/pytorch-normalizing-flows/nflib/flows.py:259\u001b[0m, in \u001b[0;36mNormalizingFlow.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    257\u001b[0m zs \u001b[38;5;241m=\u001b[39m [x]\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flow \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflows:\n\u001b[0;32m--> 259\u001b[0m     x, ld \u001b[38;5;241m=\u001b[39m flow\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m    260\u001b[0m     log_det \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ld\n\u001b[1;32m    261\u001b[0m     zs\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[0;32m~/housing-climate-main/notebooks/../src/pytorch-normalizing-flows/nflib/flows.py:233\u001b[0m, in \u001b[0;36mInvertible1x1Conv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 233\u001b[0m     W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assemble_W()\n\u001b[1;32m    234\u001b[0m     z \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m@\u001b[39m W\n\u001b[1;32m    235\u001b[0m     log_det \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(torch\u001b[38;5;241m.\u001b[39mlog(torch\u001b[38;5;241m.\u001b[39mabs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS)))\n",
      "File \u001b[0;32m~/housing-climate-main/notebooks/../src/pytorch-normalizing-flows/nflib/flows.py:227\u001b[0m, in \u001b[0;36mInvertible1x1Conv._assemble_W\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assemble_W\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" assemble W from its pieces (P, L, U, S) \"\"\"\u001b[39;00m\n\u001b[0;32m--> 227\u001b[0m     L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtril(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, diagonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(torch\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim))\n\u001b[1;32m    228\u001b[0m     U \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtriu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mU, diagonal\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    229\u001b[0m     W \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mP \u001b[38;5;241m@\u001b[39m L \u001b[38;5;241m@\u001b[39m (U \u001b[38;5;241m+\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mS))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nf_dict = nfg.train_model(df_sample[[\"x_norm\", \"y_norm\"]], \n",
    "                          num_layers = num_layers_nf, \n",
    "                          hidden_features = hidden_features_nf,\n",
    "                          num_epochs = num_epochs_nf, \n",
    "                          opt_name = opt_nf, \n",
    "                          batch_dim = batch_dim_nf, \n",
    "                          flow_name = flow_name,\n",
    "                          hide_progress = False, \n",
    "                          path = path_nf,\n",
    "                          model_settings = model_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    for prov in data[\"prov_abbrv\"].sort_values().unique():\n",
    "        print(prov)\n",
    "        try:\n",
    "            date = \"241203\" + prov\n",
    "            # id = \"_\".join([str(u) for u in [num_layers_nf, hidden_features_nf, num_epochs_nf, lr_nf_, opt_nf, flow_name, batch_dim_nf, date]])\n",
    "\n",
    "            path_nf = jl_vae.path_pop_synth + f\"nf_models/nf_{date}.pkl\"\n",
    "            \n",
    "            df_prov_full = jl_vae.get_df_prov(prov, dropna = False)\n",
    "\n",
    "            df_prov_full = df_prov_full[[u for u in jl_vae.cols if u not in [\"prov_abbrv\"]] + [\"x_norm\", \"y_norm\"]].assign(flag_air_conditioning_Missing = lambda x: x[\"flag_air_conditioning\"] == \"Missing\",\n",
    "                                                            flag_multi_floor_Missing = lambda x: x[\"flag_multi_floor\"] == \"Missing\").replace(\"Missing\",0).astype(float)\n",
    "            df_prov_dropna = jl_vae.get_df_prov(prov, dropna = True, drop_cols = [\"flag_air_conditioning\", \"flag_multi_floor\", 'floor_0.0', 'floor_1.0',\n",
    "                                                                                  'floor_2.0', 'floor_3.0', 'floor_Missing', 'floor_plus_4'])\n",
    "\n",
    "            model_settings = {\"num_layers_nf\": num_layers_nf, \"hidden_features_nf\": hidden_features_nf, \n",
    "                            \"num_epochs_nf\": num_epochs_nf, \"lr_nf\": lr_nf, \"opt_nf\": opt_nf, \"flow_name\": flow_name,\n",
    "                            \"batch_dim\": batch_dim_nf, \"date\": date, \"prov\": prov}\n",
    "\n",
    "\n",
    "            print(prov, \"NF\")\n",
    "            t0 = time()\n",
    "            \n",
    "            # nf_dict = nfg.train_model(df_prov_full[[\"x_norm\", \"y_norm\"]], \n",
    "            #                         num_layers = num_layers_nf, \n",
    "            #                         hidden_features = hidden_features_nf,\n",
    "            #                         num_epochs = num_epochs_nf, \n",
    "            #                         opt_name = opt_nf, \n",
    "            #                         batch_dim = batch_dim_nf, \n",
    "            #                         flow_name = flow_name,\n",
    "            #                         hide_progress = True, \n",
    "            #                         path = path_nf,\n",
    "            #                         model_settings = model_settings)\n",
    "            nf_dict = load_dict(path_nf)\n",
    "\n",
    "            t1 = time()\n",
    "            print(prov, \"NF\", round(t1 - t0, 2))\n",
    "            \n",
    "\n",
    "            for j,df_vae in enumerate([df_prov_full.copy(), df_prov_dropna.copy()]):\n",
    "                if j:\n",
    "                    continue\n",
    "                print(prov, j, \"VAE\")\n",
    "                date = \"240107\" + prov\n",
    "                \n",
    "                t0 = time()\n",
    "                inv_coord = nf_dict[\"flow\"].flow.forward(torch.tensor(np.array(df_vae[[\"x_norm\", \"y_norm\"]]), dtype = torch.float32))\n",
    "                df_vae[[\"y_latent\", \"x_latent\"]] = torch.sigmoid(inv_coord[0][-1]).detach().numpy()\n",
    "\n",
    "                if j:\n",
    "                    df_vae.drop(columns = [u for u in df_vae.columns if \"Missing\" in u], inplace = True)\n",
    "\n",
    "                # df_vae.drop(columns = [u for u in df_vae.columns if \"floor\" in u], inplace = True)\n",
    "                # df_vae.drop(columns = [u for u in df_vae.columns if \"ANNO\" in u], inplace = True)\n",
    "                # df_vae.drop(columns = [u for u in df_vae.columns if \"COD\" in u], inplace = True)\n",
    "                # df_vae.drop(columns = [u for u in df_vae.columns if \"latent\" in u], inplace = True)\n",
    "                # df_vae.drop(columns = [u for u in [\"flag_geo_valid\", \"log_mq\"] if u in df_vae.columns], inplace = True)\n",
    "                df_vae.drop(columns = [u for u in [\"flag_geo_valid\"] if u in df_vae.columns], inplace = True)\n",
    "                # df_vae.drop(columns = [\"x\", \"y\"], inplace = True)\n",
    "                \n",
    "                hidden_dims_vae = [df_vae.drop(columns = [\"x\", \"y\", \"x_norm\", \"y_norm\"]).shape[1]] + middle_hidden_dims_vae \n",
    "\n",
    "                vae = jl_vae.VariationalAutoencoder(full_df = df_vae.astype(np.float32),\n",
    "                                                    latent_dims = latent_dims_vae,\n",
    "                                                    hidden_dims = hidden_dims_vae,\n",
    "                                                    )\n",
    "                \n",
    "                vae.train(epochs = epochs_vae,\n",
    "                        lr = lr_vae,\n",
    "                        hide_tqdm = True,\n",
    "                        verbose = False, \n",
    "                        opt_name = opt_vae,\n",
    "                        batch_size = 100,\n",
    "                        weight_reconstruction = 10, #6,\n",
    "                        weight_kl = 0.1,\n",
    "                        weights_geo = 30, # 20,\n",
    "                        kl_annealing = False\n",
    "                        )\n",
    "                \n",
    "\n",
    "                path_vae = jl_vae.path_pop_synth + f\"vae_models/vae_{['full', 'dropna'][j]}_{date}.pkl\"\n",
    "                path_settings = jl_vae.path_pop_synth + f\"vae_models/settings_{['full', 'dropna'][j]}_{date}.pkl\"\n",
    "                \n",
    "                vae.save(path_vae)\n",
    "                vae.save_settings(path_settings)\n",
    "                \n",
    "                df_sample = vae.get_sample_from_vae(nf_dict = nf_dict)\n",
    "\n",
    "                # df_sample = utils.spatial_matching_ABM(df_sample.rename(columns = {\"x\":\"GEO_LONGITUDINE_BENE_ROUNDED\", \n",
    "                #                                                                 \"y\":\"GEO_LATITUDINE_BENE_ROUNDED\"}), \n",
    "                #                                                                 geo_data_dict[\"hydro_risk\"], \n",
    "                #                                                                 geo_data_dict[\"census\"], \n",
    "                #                                                                 geo_data_dict[\"omi_og\"], \n",
    "                #                                                                 geo_data_dict[\"cap\"])\n",
    "                \n",
    "                df_sample.to_csv(jl_vae.path_pop_synth + f\"pop_samples/synthetic_pop_{['full', 'dropna'][j]}_{date}.csv\")\n",
    "\n",
    "                t1 = time()\n",
    "                print(prov, \"VAE\", j, round(t1 - t0, 2))\n",
    "        except:\n",
    "            print(\"Error\", prov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synpop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
