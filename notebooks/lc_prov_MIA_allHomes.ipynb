{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "In this script, I will do the MIA analyses, considering the distance for all homes\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# import libraries\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots as sbp \n",
    "from importlib import reload\n",
    "import jl_vae\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# import jl_nflows_geo_coordinates_2 as nfg\n",
    "# from jl_nflows_geo_coordinates import load_nf as load_dict\n",
    "\n",
    "from _51_abm_functions import cod_prov_abbrv_df\n",
    "\n",
    "# Global Spatial Autocorrelation\n",
    "from spatial_autocorrelation import get_moransI, moransI_scatterplot, hypothesis_testing\n",
    "# Local Spatial Autocorrelation\n",
    "from spatial_autocorrelation import get_localMoransI, LISA_scatterplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import gower\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ConvertBool2number(df):\n",
    "    \"\"\"Function to convert boolean columns to numeric\"\"\"\n",
    "    bool_cols = df.select_dtypes(include=bool).columns\n",
    "    df[bool_cols] = df[bool_cols].astype(float)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def Distance_x1(x1,metric='euclidean'):\n",
    "    \"\"\"Function to compute the distance between all point in a set, exception made for the point at hand\"\"\"\n",
    "    # Distance matrix\n",
    "    if(metric=='euclidean'):\n",
    "        dists = pairwise_distances(x1.values, metric='euclidean') \n",
    "    elif(metric=='norm1'):\n",
    "        dists = pairwise_distances(x1.values, metric='minkowski', p=1)\n",
    "    elif(metric == 'gower'):\n",
    "        dists = gower.gower_matrix(x1)\n",
    "\n",
    "    np.fill_diagonal(dists, np.inf) \n",
    "    #del df2\n",
    "    # take the minimum distances\n",
    "    min_dists = dists.min(axis=1)\n",
    "\n",
    "    return min_dists\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def min_distance_to_synth(x_real, x_synth, metric=\"euclidean\"):\n",
    "    \"\"\"This function returns the minimum distance between real and synthetic data\"\"\"\n",
    "    if(metric=='euclidean'):\n",
    "        dists = pairwise_distances(x_real, x_synth, metric=metric)\n",
    "    elif(metric=='norm1'):\n",
    "        dists = pairwise_distances(x_real, x_synth, metric='minkowski', p=1)\n",
    "    elif(metric=='gower'):\n",
    "        dists = gower.gower_matrix(x_real, x_synth)\n",
    "    \n",
    "    return dists.min(axis=1) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def DataPreparation_Privacy1(data):\n",
    "    \"\"\"Function to prepare the data for the privacy analyses\"\"\"\n",
    "    \n",
    "\n",
    "    for key in data.keys():\n",
    "        data[key] = ConvertBool2number(data[key])\n",
    "\n",
    "    df = pd.concat(data, ignore_index=False)\n",
    "    df = df.reset_index(level=0).rename(columns={\"level_0\": \"origine\"})\n",
    "\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    #scaler = MinMaxScaler()\n",
    "    df[num_cols] = (df[num_cols]-df[num_cols].min())/(df[num_cols].max()-df[num_cols].min())\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    data_out = dict()\n",
    "    for i in data.keys():\n",
    "        a = df.loc[df.origine == i,:].drop(columns='origine').reset_index(drop=True)\n",
    "        data_out[i] = a\n",
    "\n",
    "    return data_out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Train_Test_set(df_train,df_test,f=0.80,seed=42):\n",
    "    df_train_1 = df_train.sample(frac=f,random_state=seed)\n",
    "    df_train_2 = df_train.drop(index=df_train_1.index)\n",
    "\n",
    "    df_test_1 = df_test.sample(frac=f,random_state=seed)\n",
    "    df_test_2 = df_test.drop(index=df_test_1.index)\n",
    "\n",
    "    df_train_out = pd.concat([df_train_1,df_test_1]).reset_index(drop=True)\n",
    "    df_test_out = pd.concat([df_train_2,df_test_2]).reset_index(drop=True)\n",
    "\n",
    "    \"\"\"Xtrain = df_train.data.values.reshape(-1,1)\n",
    "    ytrain = df_train.label.values\n",
    "\n",
    "    Xtest = df_test.data.values.reshape(-1,1)\n",
    "    ytest = df_test.label.values\"\"\"\n",
    "\n",
    "    return df_train_out, df_test_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MIA_Table_Test(df_train,df_test,control_data,seed = 42):\n",
    "    \"\"\"\n",
    "    This function returns several dataframe, each dataframe reports the performance according to a measure for the classification problem.\n",
    "    The output dataframes have along the rows the synthetic populations nd along the columns the classificators.\n",
    "    \n",
    "    \"\"\"\n",
    "    res_rocauc=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_aucpr=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_precision=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_recall=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_f1=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "\n",
    "    for i in control_data:\n",
    "        roc_auc_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        aucpr_list = []\n",
    "\n",
    "        X = df_train[i].values.reshape(-1,1)\n",
    "        y = df_train['label_'+i].values\n",
    "\n",
    "        Xtest = df_test[i].values.reshape(-1,1)\n",
    "        ytest = df_test['label_'+i].values\n",
    "\n",
    "        # Logistic Regression\n",
    "        model = LogisticRegression(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # GaussianNB\n",
    "        model = GaussianNB()\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # KNeighbors\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # DecisionTree\n",
    "        model = DecisionTreeClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # Random Forest\n",
    "        model = RandomForestClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # SVC\n",
    "        model = SVC(probability=True, random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # MLP\n",
    "        model = MLPClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # wide output dataframe\n",
    "        res_rocauc.loc[i,:] = roc_auc_list\n",
    "        res_aucpr.loc[i,:] = aucpr_list\n",
    "        res_precision.loc[i,:] = precision_list\n",
    "        res_recall.loc[i,:] = recall_list\n",
    "        res_f1.loc[i,:] = f1_list\n",
    "\n",
    "    # long output dataframe\n",
    "    res_rocauc = res_rocauc.reset_index(drop=False,names='pop_name')\n",
    "    res_rocauc = pd.melt(res_rocauc,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_aucpr = res_aucpr.reset_index(drop=False,names='pop_name')\n",
    "    res_aucpr = pd.melt(res_aucpr,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_precision = res_precision.reset_index(drop=False,names='pop_name')\n",
    "    res_precision = pd.melt(res_precision,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_recall = res_recall.reset_index(drop=False,names='pop_name')\n",
    "    res_recall = pd.melt(res_recall,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_f1 = res_f1.reset_index(drop=False,names='pop_name')\n",
    "    res_f1 = pd.melt(res_f1,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "\n",
    "    return res_rocauc, res_aucpr, res_precision, res_recall, res_f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAIN\n",
    "\n",
    "metrics = ['euclidean','norm1', 'gower'] #'euclidean',\n",
    "folder_path = '/data/housing/data/intermediate/lc_privacyStats/AllHomes_MIA/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    MIA_res_auc_roc = pd.DataFrame()\n",
    "    MIA_res_auc_pr = pd.DataFrame()\n",
    "\n",
    "    df_train = pd.DataFrame()\n",
    "    df_test = pd.DataFrame()\n",
    "\n",
    "    for file in tqdm(sorted(glob(f'/data/housing/data/intermediate/jl_pop_synth/isp_baselines/all_baselines_*.pickle'))[0:4]):\n",
    "        prov = file.split(\".\")[-2][-2:]\n",
    "        # data loading\n",
    "        with open(file, 'rb') as f:\n",
    "            all_baselines = pickle.load(f)\n",
    "\n",
    "        all_baselines['df_excluded'] = all_baselines['df_real'][~all_baselines['df_real'].index.isin(all_baselines['df_real95'].index)]\n",
    "\n",
    "        del all_baselines['df_real']\n",
    "\n",
    "        # data preparation\n",
    "        data = DataPreparation_Privacy1(data=all_baselines)\n",
    "\n",
    "        control_data = [i for i in data.keys() if '95' in i and 'real' not in i]\n",
    "\n",
    "        # the features are the distances\n",
    "        \n",
    "        for i in control_data:\n",
    "            train_features = min_distance_to_synth(data['df_real95'].values, data[i].values,metric=metric)#.reshape(-1,1)\n",
    "            y_train = np.array([1]*len(train_features))\n",
    "            holdout_features = min_distance_to_synth(data['df_excluded'].values, data[i].values,metric=metric)#.reshape(-1,1)\n",
    "            y_test = np.array([0]*len(holdout_features))\n",
    "\n",
    "            df_train_one_pop = pd.DataFrame({i:train_features,'label_'+i:y_train})\n",
    "            df_test_one_pop = pd.DataFrame({i:holdout_features,'label'+i:y_test})\n",
    "\n",
    "            df_train = pd.concat([df_train,df_train_one_pop],axis=1)\n",
    "            df_test = pd.concat([df_test,df_test_one_pop],axis=1)\n",
    "\n",
    "\n",
    "    # defining training and testing set\n",
    "    DF_train, DF_test = Get_Train_Test_set(df_train,df_test)\n",
    "\n",
    "    res_auc_roc, res_auc_pr, _, _, _ = MIA_Table_Test(DF_train,DF_test,control_data)\n",
    "\n",
    "    # saving\n",
    "    MIA_res_auc_roc.to_csv(folder_path+f'MIA_auc_roc_{metric}.csv',index=False)\n",
    "    MIA_res_auc_pr.to_csv(folder_path+f'MIA_auc_pr_{metric}.csv',index=False)\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
