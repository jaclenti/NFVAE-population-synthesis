{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots as sbp \n",
    "from importlib import reload\n",
    "import jl_vae\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# import jl_nflows_geo_coordinates_2 as nfg\n",
    "# from jl_nflows_geo_coordinates import load_nf as load_dict\n",
    "\n",
    "from _51_abm_functions import cod_prov_abbrv_df\n",
    "\n",
    "# Global Spatial Autocorrelation\n",
    "from spatial_autocorrelation import get_moransI, moransI_scatterplot, hypothesis_testing\n",
    "# Local Spatial Autocorrelation\n",
    "from spatial_autocorrelation import get_localMoransI, LISA_scatterplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import gower\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "def ConvertBool2number(df):\n",
    "    \"\"\"Function to convert boolean columns to numeric\"\"\"\n",
    "    bool_cols = df.select_dtypes(include=bool).columns\n",
    "    df[bool_cols] = df[bool_cols].astype(float)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def DataPreparation_Privacy(data,keys):\n",
    "    \"\"\"Function to prepare the data for the privacy analyses\"\"\"\n",
    "    \n",
    "    df_real = ConvertBool2number(data['df_real']) \n",
    "    df_real95 = ConvertBool2number(data['df_real95'])\n",
    "    df_excluded = ConvertBool2number(df_real[~df_real.index.isin(df_real95.index)])\n",
    "    df_real95['descr'] = 0 #'real95'\n",
    "    df_excluded['descr'] = 1 #'real_excluded'\n",
    "\n",
    "    # nf + VAE\n",
    "    df_nfvae = ConvertBool2number(data['df_nfvae']) \n",
    "    df_nfvae95 = ConvertBool2number(data['df_nfvae95']) \n",
    "    df_nfvae['descr'] = 2 #'nfvae'\n",
    "    df_nfvae95['descr'] = 3 #'nfvae95'\n",
    "    # ablation (only VAE)\n",
    "    df_vae = ConvertBool2number(data['df_ablation'])\n",
    "    df_vae95 = ConvertBool2number(data['df_ablation95'])\n",
    "    df_vae['descr'] = 4 #'vae'\n",
    "    df_vae95['descr'] = 5 #'vae95'\n",
    "    # ipf\n",
    "    df_ipf = ConvertBool2number(data['df_ipf']) \n",
    "    df_ipf95 = ConvertBool2number(data['df_ipf95']) \n",
    "    df_ipf['descr'] = 6 #'ipf'\n",
    "    df_ipf95['descr'] = 7 #'ipf95'\n",
    "    # copula + nf (95%)\n",
    "    df_copulanf = ConvertBool2number(data['df_copula_nf'])\n",
    "    df_copulanf95 = ConvertBool2number(data['df_copula_nf95'])\n",
    "    df_copulanf['descr'] = 8 #'copulanf'\n",
    "    df_copulanf95['descr'] = 9 #'copulanf95'\n",
    "    # copula (95%)\n",
    "    df_copula = ConvertBool2number(data['df_copula_ablation'])\n",
    "    df_copula95 = ConvertBool2number(data['df_copula_ablation95'])\n",
    "    df_copula['descr'] = 10 #'copula'\n",
    "    df_copula95['descr'] = 11 #'copula95'\n",
    "\n",
    "    df = pd.concat([df_real95,df_excluded,\n",
    "                df_nfvae,df_nfvae95,\n",
    "                df_vae,df_vae95,\n",
    "                df_ipf,df_ipf95,\n",
    "                df_copulanf,df_copulanf95,\n",
    "                df_copula,df_copula95])\n",
    "    \n",
    "    df = (df-df.min())/(df.max()-df.min()) # all populations (for the same province) are scaled within the same metric space\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    unique_descr = df.descr.unique()\n",
    "    data_out = dict()\n",
    "    for i in range(len(keys)):\n",
    "        a = df.loc[df.descr == unique_descr[i],:].drop(columns='descr').reset_index(drop=True)\n",
    "        data_out[keys[i]] = a\n",
    "\n",
    "    return data_out\n",
    "\n",
    "\n",
    "def Distance_x1(x1,metric='euclidean'):\n",
    "    \"\"\"Function to compute the distance between all point in a set, exception made for the point at hand\"\"\"\n",
    "    # Distance matrix\n",
    "    if(metric=='euclidean'):\n",
    "        dists = pairwise_distances(x1.values, metric='euclidean') \n",
    "    elif(metric=='norm1'):\n",
    "        dists = pairwise_distances(x1.values, metric='minkowski', p=1)\n",
    "    elif(metric == 'gower'):\n",
    "        dists = gower.gower_matrix(x1)\n",
    "\n",
    "    np.fill_diagonal(dists, np.inf) \n",
    "    #del df2\n",
    "    # take the minimum distances\n",
    "    min_dists = dists.min(axis=1)\n",
    "\n",
    "    return min_dists\n",
    "\n",
    "def TableDistance(data, control_data, test_data = 'df_real95',metric='euclidean'):\n",
    "    \"\"\"Function that computes the distance between the real records to the synthetic ones, returning some statistics\"\"\"\n",
    "    \n",
    "    #df1 = data[test_data] # dataframe containing the data considered in computing the distances\n",
    "    res = pd.DataFrame(columns=['mean','std'])\n",
    "    for i in control_data:\n",
    "        # prov_res = pd.DataFrame(columns=['pop_name','min_dist'])\n",
    "        # Distance matrix\n",
    "        if(metric=='euclidean'):\n",
    "            dists = pairwise_distances(data[test_data].values,data[i].values, metric='euclidean') \n",
    "        elif(metric=='norm1'):\n",
    "            dists = pairwise_distances(data[test_data].values,data[i].values, metric='minkowski', p=1)\n",
    "        elif(metric == 'gower'):\n",
    "            dists = gower.gower_matrix(data[test_data].values,data[i].values)\n",
    "        \n",
    "        # take the minimum distances\n",
    "        min_dists = dists.min(axis=1)\n",
    "        res.loc[i,:] = [np.mean(min_dists), np.std(min_dists)]\n",
    "        \n",
    "    min_dists_benchmark = Distance_x1(data[test_data],metric=metric)\n",
    "    res.loc['Benchmark (train data -- real95)',:] = [np.mean(min_dists_benchmark), np.std(min_dists_benchmark)]\n",
    "    \n",
    "    res = res.reset_index(drop=False,names='pop_name')\n",
    "    res = pd.melt(res,id_vars=[\"pop_name\"],var_name=['min_distance'],value_name='score')\n",
    "    return res #, min_dists\n",
    "\n",
    "def TableNNDR(data, control_data,test_data = 'df_real95',metric='euclidean'):\n",
    "    \"\"\"Function that compuets the ratio between the minimum and the second minimum distance between a synthetic and real record\"\"\"\n",
    "\n",
    "    res = pd.DataFrame(columns=['mean_train','std_train']) #,'mean_test','std_test'\n",
    "    for i in control_data:\n",
    "        # Distance matrix\n",
    "        if(metric=='euclidean'):\n",
    "            dists_train = pairwise_distances(data[i].values,data[test_data].values, metric='euclidean') \n",
    "            #dists_test = pairwise_distances(data[i].values,data['real_excluded'].values, metric='euclidean') \n",
    "        elif(metric=='norm1'):\n",
    "            dists_train = pairwise_distances(data[i].values,data[test_data].values, metric='minkowski', p=1)\n",
    "            #dists_test = pairwise_distances(data[i].values,data['real_excluded'].values, metric='minkowski', p=1)\n",
    "        elif(metric == 'gower'):\n",
    "            dists_train = gower.gower_matrix(data[i].values,data[test_data].values,)\n",
    "            #dists_test = gower.gower_matrix(data[i].values,data['real_excluded'].values)\n",
    "        \n",
    "        # take the minimum distances\n",
    "        sorted_rows_train = np.sort(dists_train,axis=1)\n",
    "        #sorted_rows_test = np.sort(dists_test,axis=1)\n",
    "\n",
    "        min_train = sorted_rows_train[:,0]\n",
    "        #min_test = sorted_rows_test[:,0]\n",
    "\n",
    "        second_min_train = sorted_rows_train[:,1]\n",
    "        #second_min_test = sorted_rows_test[:,1]\n",
    "\n",
    "        ratio_train = min_train/second_min_train\n",
    "        #ratio_test = min_test/second_min_test\n",
    "\n",
    "\n",
    "        #res.loc[i,:] = [np.round(np.mean(ratio_train),3), np.round(np.std(ratio_train),3), np.round(np.mean(ratio_test),3), np.round(np.std(ratio_test),3)]\n",
    "        res.loc[i,:] = [np.mean(ratio_train), np.std(ratio_train)]\n",
    "    res = res.reset_index(drop=False,names='pop_name')\n",
    "    res = pd.melt(res,id_vars=[\"pop_name\"],var_name=['distance_ratio'],value_name='score')\n",
    "        \n",
    "    return res #, ratio_train\n",
    "\n",
    "\n",
    "def min_distance_to_synth(x_real, x_synth, metric=\"euclidean\"):\n",
    "    \"\"\"This function returns the minimum distance between real and synthetic data\"\"\"\n",
    "    if(metric=='euclidean'):\n",
    "        dists = pairwise_distances(x_real, x_synth, metric=metric)\n",
    "    elif(metric=='norm1'):\n",
    "        dists = pairwise_distances(x_real, x_synth, metric='minkowski', p=1)\n",
    "    elif(metric=='gower'):\n",
    "        dists = gower.gower_matrix(x_real, x_synth)\n",
    "    \n",
    "    return dists.min(axis=1) \n",
    "\n",
    "\n",
    "def MIA_Table_Test(data,control_data,metric='euclidean',f=0.8,seed = 42):\n",
    "    \"\"\"\n",
    "    This function returns several dataframe, each dataframe reports the performance according to a measure for the classification problem.\n",
    "    The output dataframes have along the rows the synthetic populations nd along the columns the classificators.\n",
    "    \n",
    "    \"\"\"\n",
    "    res_rocauc=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_aucpr=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_precision=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_recall=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_f1=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "\n",
    "    for i in control_data:\n",
    "        roc_auc_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        aucpr_list = []\n",
    "\n",
    "        # the features are the distances\n",
    "        train_features = min_distance_to_synth(data['df_real95'].values, data[i].values,metric=metric)#.reshape(-1,1)\n",
    "        y_train = np.array([1]*len(train_features))\n",
    "        holdout_features = min_distance_to_synth(data['df_excluded'].values, data[i].values,metric=metric)#.reshape(-1,1)\n",
    "        y_test = np.array([0]*len(holdout_features))\n",
    "\n",
    "        df_train = pd.DataFrame({'data':train_features,'label':y_train})\n",
    "        df_test = pd.DataFrame({'data':holdout_features,'label':y_test})\n",
    "\n",
    "        df_train_1 = df_train.sample(frac=f,random_state=seed)\n",
    "        df_train_2 = df_train.drop(index=df_train_1.index)\n",
    "\n",
    "        df_test_1 = df_test.sample(frac=f,random_state=seed)\n",
    "        df_test_2 = df_test.drop(index=df_test_1.index)\n",
    "\n",
    "        df_train = pd.concat([df_train_1,df_test_1]).reset_index(drop=True)\n",
    "        df_test = pd.concat([df_train_2,df_test_2]).reset_index(drop=True)\n",
    "\n",
    "        X = df_train.data.values.reshape(-1,1)\n",
    "        y = df_train.label.values\n",
    "\n",
    "        Xtest = df_test.data.values.reshape(-1,1)\n",
    "        ytest = df_test.label.values\n",
    "\n",
    "        # Logistic Regression\n",
    "        model = LogisticRegression(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # GaussianNB\n",
    "        model = GaussianNB()\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # KNeighbors\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # DecisionTree\n",
    "        model = DecisionTreeClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # Random Forest\n",
    "        model = RandomForestClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # SVC\n",
    "        model = SVC(probability=True, random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # MLP\n",
    "        model = MLPClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # wide output dataframe\n",
    "        res_rocauc.loc[i,:] = roc_auc_list\n",
    "        res_aucpr.loc[i,:] = aucpr_list\n",
    "        res_precision.loc[i,:] = precision_list\n",
    "        res_recall.loc[i,:] = recall_list\n",
    "        res_f1.loc[i,:] = f1_list\n",
    "\n",
    "    # long output dataframe\n",
    "    res_rocauc = res_rocauc.reset_index(drop=False,names='pop_name')\n",
    "    res_rocauc = pd.melt(res_rocauc,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_aucpr = res_aucpr.reset_index(drop=False,names='pop_name')\n",
    "    res_aucpr = pd.melt(res_aucpr,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_precision = res_precision.reset_index(drop=False,names='pop_name')\n",
    "    res_precision = pd.melt(res_precision,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_recall = res_recall.reset_index(drop=False,names='pop_name')\n",
    "    res_recall = pd.melt(res_recall,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_f1 = res_f1.reset_index(drop=False,names='pop_name')\n",
    "    res_f1 = pd.melt(res_f1,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "\n",
    "    return res_rocauc, res_aucpr, res_precision, res_recall, res_f1\n",
    "\n",
    "\n",
    "\n",
    "def DataPreparation_Privacy1(data):\n",
    "    \"\"\"Function to prepare the data for the privacy analyses\"\"\"\n",
    "    \n",
    "\n",
    "    for key in data.keys():\n",
    "        data[key] = ConvertBool2number(data[key])\n",
    "\n",
    "    df = pd.concat(data, ignore_index=False)\n",
    "    df = df.reset_index(level=0).rename(columns={\"level_0\": \"origine\"})\n",
    "\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    #scaler = MinMaxScaler()\n",
    "    df[num_cols] = (df[num_cols]-df[num_cols].min())/(df[num_cols].max()-df[num_cols].min())\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    data_out = dict()\n",
    "    for i in data.keys():\n",
    "        a = df.loc[df.origine == i,:].drop(columns='origine').reset_index(drop=True)\n",
    "        data_out[i] = a\n",
    "\n",
    "    return data_out\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [1:27:06<00:00, 49.30s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/106 [00:41<11:26,  6.86s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     35\u001b[39m res_dist = pd.concat([res_dist,dist])\n\u001b[32m     37\u001b[39m \u001b[38;5;66;03m# ratios\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m ratio = TableNNDR(data=data, control_data=control_data,test_data = \u001b[33m'\u001b[39m\u001b[33mdf_real95\u001b[39m\u001b[33m'\u001b[39m,metric=\u001b[33m'\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     39\u001b[39m ratio[\u001b[33m'\u001b[39m\u001b[33mprov\u001b[39m\u001b[33m'\u001b[39m] = prov\n\u001b[32m     41\u001b[39m res_ratio = pd.concat([res_ratio,ratio])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 163\u001b[39m, in \u001b[36mTableNNDR\u001b[39m\u001b[34m(data, control_data, test_data, metric)\u001b[39m\n\u001b[32m    159\u001b[39m     dists_train = gower.gower_matrix(data[i].values,data[test_data].values,)\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m#dists_test = gower.gower_matrix(data[i].values,data['real_excluded'].values)\u001b[39;00m\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# take the minimum distances\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m sorted_rows_train = np.sort(dists_train,axis=\u001b[32m1\u001b[39m)\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m#sorted_rows_test = np.sort(dists_test,axis=1)\u001b[39;00m\n\u001b[32m    166\u001b[39m min_train = sorted_rows_train[:,\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/synpop/lib/python3.11/site-packages/numpy/core/fromnumeric.py:1017\u001b[39m, in \u001b[36msort\u001b[39m\u001b[34m(a, axis, kind, order)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     a = asanyarray(a).copy(order=\u001b[33m\"\u001b[39m\u001b[33mK\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m a.sort(axis=axis, kind=kind, order=order)\n\u001b[32m   1018\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "#%% MAIN\n",
    "\n",
    "\n",
    "\n",
    "metrics = ['euclidean', 'norm1', 'gower']\n",
    "\n",
    "for metric in metrics:\n",
    "    print(metric)\n",
    "\n",
    "    res_dist = pd.DataFrame()\n",
    "    res_ratio = pd.DataFrame()\n",
    "\n",
    "    MIA_res_auc_roc = pd.DataFrame()\n",
    "    MIA_res_auc_pr = pd.DataFrame()\n",
    "\n",
    "    for file in tqdm(sorted(glob(f'/data/housing/data/intermediate/jl_pop_synth/isp_baselines/all_baselines_*.pickle'))):\n",
    "        prov = file.split(\".\")[-2][-2:]\n",
    "        # data loading\n",
    "        with open(file, 'rb') as f:\n",
    "            all_baselines = pickle.load(f)\n",
    "\n",
    "        all_baselines['df_excluded'] = all_baselines['df_real'][~all_baselines['df_real'].index.isin(all_baselines['df_real95'].index)]\n",
    "\n",
    "        del all_baselines['df_real']\n",
    "\n",
    "        # data preparation\n",
    "        data = DataPreparation_Privacy1(data=all_baselines)\n",
    "\n",
    "        control_data = [i for i in data.keys() if '95' in i and 'real' not in i]\n",
    "\n",
    "        # distances\n",
    "        dist = TableDistance(data = data, control_data=control_data, test_data = 'df_real95',metric='euclidean')\n",
    "        dist['prov'] = prov\n",
    "\n",
    "        res_dist = pd.concat([res_dist,dist])\n",
    "\n",
    "        # ratios\n",
    "        ratio = TableNNDR(data=data, control_data=control_data,test_data = 'df_real95',metric='euclidean')\n",
    "        ratio['prov'] = prov\n",
    "\n",
    "        res_ratio = pd.concat([res_ratio,ratio])\n",
    "\n",
    "        # MIA\n",
    "        res_auc_roc, res_auc_pr, _, _, _ = MIA_Table_Test(data,control_data,metric='euclidean',f=0.8,seed = 42)\n",
    "        res_auc_roc['prov'] = prov\n",
    "        res_auc_pr['prov'] = prov\n",
    "\n",
    "        MIA_res_auc_roc = pd.concat([MIA_res_auc_roc,res_auc_roc])\n",
    "        MIA_res_auc_pr = pd.concat([MIA_res_auc_pr,res_auc_pr])\n",
    "\n",
    "    # saving\n",
    "    folder_path = '/data/housing/data/intermediate/lc_privacyStats/'\n",
    "\n",
    "    res_dist.to_csv(folder_path+f'distances_{metric}.csv',index=False)\n",
    "    res_ratio.to_csv(folder_path+f'ratio_{metric}.csv',index=False)\n",
    "    MIA_res_auc_roc.to_csv(folder_path+f'MIA_auc_roc_{metric}.csv',index=False)\n",
    "    MIA_res_auc_pr.to_csv(folder_path+f'MIA_auc_pr_{metric}.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pop_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "min_distance",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "prov",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "89247e3f-97ab-4dd7-b420-9d6099133b89",
       "rows": [
        [
         "0",
         "df_nfvae95",
         "mean",
         "1.3505102348487648",
         "AG"
        ],
        [
         "1",
         "df_ablation95",
         "mean",
         "1.0629111879902544",
         "AG"
        ],
        [
         "2",
         "df_copula_nf95",
         "mean",
         "0.5466806983303022",
         "AG"
        ],
        [
         "3",
         "df_copula_ablation95",
         "mean",
         "0.5580195430539755",
         "AG"
        ],
        [
         "4",
         "df_shuffle_province_bins95",
         "mean",
         "0.2755662509539653",
         "AG"
        ],
        [
         "5",
         "df_shuffle_cap_bins95",
         "mean",
         "0.1685211455222212",
         "AG"
        ],
        [
         "6",
         "df_shuffle_province_num95",
         "mean",
         "0.257242858706995",
         "AG"
        ],
        [
         "7",
         "df_shuffle_cap_num95",
         "mean",
         "0.1277141749491648",
         "AG"
        ],
        [
         "8",
         "Benchmark (train data -- real95)",
         "mean",
         "0.2385106922842093",
         "AG"
        ],
        [
         "9",
         "df_nfvae95",
         "std",
         "0.7630082579627545",
         "AG"
        ],
        [
         "10",
         "df_ablation95",
         "std",
         "0.6532184420728332",
         "AG"
        ],
        [
         "11",
         "df_copula_nf95",
         "std",
         "0.3489023943514091",
         "AG"
        ],
        [
         "12",
         "df_copula_ablation95",
         "std",
         "0.3456360507823902",
         "AG"
        ],
        [
         "13",
         "df_shuffle_province_bins95",
         "std",
         "0.305114164335678",
         "AG"
        ],
        [
         "14",
         "df_shuffle_cap_bins95",
         "std",
         "0.2536734414942628",
         "AG"
        ],
        [
         "15",
         "df_shuffle_province_num95",
         "std",
         "0.32761973464557",
         "AG"
        ],
        [
         "16",
         "df_shuffle_cap_num95",
         "std",
         "0.250982597437813",
         "AG"
        ],
        [
         "17",
         "Benchmark (train data -- real95)",
         "std",
         "0.3491019164660714",
         "AG"
        ],
        [
         "18",
         "df_nfvae95",
         "mean",
         "0.9822806243854564",
         "AL"
        ],
        [
         "19",
         "df_ablation95",
         "mean",
         "0.7594959225883464",
         "AL"
        ],
        [
         "20",
         "df_copula_nf95",
         "mean",
         "0.3836660537187403",
         "AL"
        ],
        [
         "21",
         "df_copula_ablation95",
         "mean",
         "0.3822642735853953",
         "AL"
        ],
        [
         "22",
         "df_shuffle_province_bins95",
         "mean",
         "0.2558260760036706",
         "AL"
        ],
        [
         "23",
         "df_shuffle_cap_bins95",
         "mean",
         "0.1859272788286753",
         "AL"
        ],
        [
         "24",
         "df_shuffle_province_num95",
         "mean",
         "0.2384382886786652",
         "AL"
        ],
        [
         "25",
         "df_shuffle_cap_num95",
         "mean",
         "0.1465972432186395",
         "AL"
        ],
        [
         "26",
         "Benchmark (train data -- real95)",
         "mean",
         "0.2365925801743128",
         "AL"
        ],
        [
         "27",
         "df_nfvae95",
         "std",
         "0.6609582801124102",
         "AL"
        ],
        [
         "28",
         "df_ablation95",
         "std",
         "0.5816352531497743",
         "AL"
        ],
        [
         "29",
         "df_copula_nf95",
         "std",
         "0.3736281343858424",
         "AL"
        ],
        [
         "30",
         "df_copula_ablation95",
         "std",
         "0.3620529100519769",
         "AL"
        ],
        [
         "31",
         "df_shuffle_province_bins95",
         "std",
         "0.2361889593135077",
         "AL"
        ],
        [
         "32",
         "df_shuffle_cap_bins95",
         "std",
         "0.2614133777194549",
         "AL"
        ],
        [
         "33",
         "df_shuffle_province_num95",
         "std",
         "0.2384059633972741",
         "AL"
        ],
        [
         "34",
         "df_shuffle_cap_num95",
         "std",
         "0.253438348038874",
         "AL"
        ],
        [
         "35",
         "Benchmark (train data -- real95)",
         "std",
         "0.2909335505405724",
         "AL"
        ],
        [
         "36",
         "df_nfvae95",
         "mean",
         "0.7005246244701733",
         "AN"
        ],
        [
         "37",
         "df_ablation95",
         "mean",
         "0.5216399636989812",
         "AN"
        ],
        [
         "38",
         "df_copula_nf95",
         "mean",
         "0.2026417634687403",
         "AN"
        ],
        [
         "39",
         "df_copula_ablation95",
         "mean",
         "0.2212832971273325",
         "AN"
        ],
        [
         "40",
         "df_shuffle_province_bins95",
         "mean",
         "0.1774431328891343",
         "AN"
        ],
        [
         "41",
         "df_shuffle_cap_bins95",
         "mean",
         "0.1191471614640077",
         "AN"
        ],
        [
         "42",
         "df_shuffle_province_num95",
         "mean",
         "0.1624117191114046",
         "AN"
        ],
        [
         "43",
         "df_shuffle_cap_num95",
         "mean",
         "0.0956956717613179",
         "AN"
        ],
        [
         "44",
         "Benchmark (train data -- real95)",
         "mean",
         "0.1350271687040686",
         "AN"
        ],
        [
         "45",
         "df_nfvae95",
         "std",
         "0.6636208625480642",
         "AN"
        ],
        [
         "46",
         "df_ablation95",
         "std",
         "0.5699871621537393",
         "AN"
        ],
        [
         "47",
         "df_copula_nf95",
         "std",
         "0.3229181089395129",
         "AN"
        ],
        [
         "48",
         "df_copula_ablation95",
         "std",
         "0.3281368439867417",
         "AN"
        ],
        [
         "49",
         "df_shuffle_province_bins95",
         "std",
         "0.1869289302932303",
         "AN"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 1908
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_name</th>\n",
       "      <th>min_distance</th>\n",
       "      <th>score</th>\n",
       "      <th>prov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_nfvae95</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.350510</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_ablation95</td>\n",
       "      <td>mean</td>\n",
       "      <td>1.062911</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_copula_nf95</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.546681</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_copula_ablation95</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.558020</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_shuffle_province_bins95</td>\n",
       "      <td>mean</td>\n",
       "      <td>0.275566</td>\n",
       "      <td>AG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>df_shuffle_province_bins95</td>\n",
       "      <td>std</td>\n",
       "      <td>0.321435</td>\n",
       "      <td>VV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>df_shuffle_cap_bins95</td>\n",
       "      <td>std</td>\n",
       "      <td>0.352986</td>\n",
       "      <td>VV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>df_shuffle_province_num95</td>\n",
       "      <td>std</td>\n",
       "      <td>0.284878</td>\n",
       "      <td>VV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>df_shuffle_cap_num95</td>\n",
       "      <td>std</td>\n",
       "      <td>0.337892</td>\n",
       "      <td>VV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1907</th>\n",
       "      <td>Benchmark (train data -- real95)</td>\n",
       "      <td>std</td>\n",
       "      <td>0.372795</td>\n",
       "      <td>VV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1908 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              pop_name min_distance     score prov\n",
       "0                           df_nfvae95         mean  1.350510   AG\n",
       "1                        df_ablation95         mean  1.062911   AG\n",
       "2                       df_copula_nf95         mean  0.546681   AG\n",
       "3                 df_copula_ablation95         mean  0.558020   AG\n",
       "4           df_shuffle_province_bins95         mean  0.275566   AG\n",
       "...                                ...          ...       ...  ...\n",
       "1903        df_shuffle_province_bins95          std  0.321435   VV\n",
       "1904             df_shuffle_cap_bins95          std  0.352986   VV\n",
       "1905         df_shuffle_province_num95          std  0.284878   VV\n",
       "1906              df_shuffle_cap_num95          std  0.337892   VV\n",
       "1907  Benchmark (train data -- real95)          std  0.372795   VV\n",
       "\n",
       "[1908 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/housing/data/intermediate/lc_privacyStats/distances_euclidean.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AG', 'AL', 'AN', 'AO', 'AP', 'AQ', 'AR', 'AT', 'AV', 'BA', 'BG',\n",
       "       'BI', 'BL', 'BN', 'BO', 'BR', 'BS', 'BT', 'BZ', 'CA', 'CB', 'CE',\n",
       "       'CH', 'CL', 'CN', 'CO', 'CR', 'CS', 'CT', 'CZ', 'EN', 'FC', 'FE',\n",
       "       'FG', 'FI', 'FM', 'FR', 'GE', 'GO', 'GR', 'IM', 'IS', 'KR', 'LC',\n",
       "       'LE', 'LI', 'LO', 'LT', 'LU', 'MB', 'MC', 'ME', 'MI', 'MN', 'MO',\n",
       "       'MS', 'MT', 'NA', 'NO', 'NU', 'OR', 'PA', 'PC', 'PD', 'PE', 'PG',\n",
       "       'PI', 'PN', 'PO', 'PR', 'PT', 'PU', 'PV', 'PZ', 'RA', 'RC', 'RE',\n",
       "       'RG', 'RI', 'RM', 'RN', 'RO', 'SA', 'SI', 'SO', 'SP', 'SR', 'SS',\n",
       "       'SV', 'TA', 'TE', 'TN', 'TO', 'TP', 'TR', 'TS', 'TV', 'UD', 'VA',\n",
       "       'VB', 'VC', 'VE', 'VI', 'VR', 'VT', 'VV'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.prov.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.prov.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)/len(df.prov.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synpop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
