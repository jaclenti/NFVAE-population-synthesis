{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"soSEHN\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.6.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"soSEHN\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"soSEHN\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div id=\"PLWMxV\"></div>\n",
       "            <script type=\"text/javascript\" data-lets-plot-script=\"library\">\n",
       "                if(!window.letsPlotCallQueue) {\n",
       "                    window.letsPlotCallQueue = [];\n",
       "                }; \n",
       "                window.letsPlotCall = function(f) {\n",
       "                    window.letsPlotCallQueue.push(f);\n",
       "                };\n",
       "                (function() {\n",
       "                    var script = document.createElement(\"script\");\n",
       "                    script.type = \"text/javascript\";\n",
       "                    script.src = \"https://cdn.jsdelivr.net/gh/JetBrains/lets-plot@v4.6.2/js-package/distr/lets-plot.min.js\";\n",
       "                    script.onload = function() {\n",
       "                        window.letsPlotCall = function(f) {f();};\n",
       "                        window.letsPlotCallQueue.forEach(function(f) {f();});\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        \n",
       "                    };\n",
       "                    script.onerror = function(event) {\n",
       "                        window.letsPlotCall = function(f) {};    // noop\n",
       "                        window.letsPlotCallQueue = [];\n",
       "                        var div = document.createElement(\"div\");\n",
       "                        div.style.color = 'darkred';\n",
       "                        div.textContent = 'Error loading Lets-Plot JS';\n",
       "                        document.getElementById(\"PLWMxV\").appendChild(div);\n",
       "                    };\n",
       "                    var e = document.getElementById(\"PLWMxV\");\n",
       "                    e.appendChild(script);\n",
       "                })()\n",
       "            </script>\n",
       "            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "sys.path += [\"../src\"]\n",
    "import utils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import subplots as sbp \n",
    "from importlib import reload\n",
    "import jl_vae\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# import jl_nflows_geo_coordinates_2 as nfg\n",
    "# from jl_nflows_geo_coordinates import load_nf as load_dict\n",
    "\n",
    "from _51_abm_functions import cod_prov_abbrv_df\n",
    "\n",
    "# Global Spatial Autocorrelation\n",
    "from spatial_autocorrelation import get_moransI, moransI_scatterplot, hypothesis_testing\n",
    "# Local Spatial Autocorrelation\n",
    "from spatial_autocorrelation import get_localMoransI, LISA_scatterplot\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import gower\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def ConvertBool2number(df):\n",
    "    \"\"\"Function to convert boolean columns to numeric\"\"\"\n",
    "    bool_cols = df.select_dtypes(include=bool).columns\n",
    "    df[bool_cols] = df[bool_cols].astype(float)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def DataPreparation_Privacy(data,keys):\n",
    "    \"\"\"Function to prepare the data for the privacy analyses\"\"\"\n",
    "    \n",
    "    df_real = ConvertBool2number(data['df_real']) \n",
    "    df_real95 = ConvertBool2number(data['df_real95'])\n",
    "    df_excluded = ConvertBool2number(df_real[~df_real.index.isin(df_real95.index)])\n",
    "    df_real95['descr'] = 0 #'real95'\n",
    "    df_excluded['descr'] = 1 #'real_excluded'\n",
    "\n",
    "    # nf + VAE\n",
    "    df_nfvae = ConvertBool2number(data['df_nfvae']) \n",
    "    df_nfvae95 = ConvertBool2number(data['df_nfvae95']) \n",
    "    df_nfvae['descr'] = 2 #'nfvae'\n",
    "    df_nfvae95['descr'] = 3 #'nfvae95'\n",
    "    # ablation (only VAE)\n",
    "    df_vae = ConvertBool2number(data['df_ablation'])\n",
    "    df_vae95 = ConvertBool2number(data['df_ablation95'])\n",
    "    df_vae['descr'] = 4 #'vae'\n",
    "    df_vae95['descr'] = 5 #'vae95'\n",
    "    # ipf\n",
    "    df_ipf = ConvertBool2number(data['df_ipf']) \n",
    "    df_ipf95 = ConvertBool2number(data['df_ipf95']) \n",
    "    df_ipf['descr'] = 6 #'ipf'\n",
    "    df_ipf95['descr'] = 7 #'ipf95'\n",
    "    # copula + nf (95%)\n",
    "    df_copulanf = ConvertBool2number(data['df_copula_nf'])\n",
    "    df_copulanf95 = ConvertBool2number(data['df_copula_nf95'])\n",
    "    df_copulanf['descr'] = 8 #'copulanf'\n",
    "    df_copulanf95['descr'] = 9 #'copulanf95'\n",
    "    # copula (95%)\n",
    "    df_copula = ConvertBool2number(data['df_copula_ablation'])\n",
    "    df_copula95 = ConvertBool2number(data['df_copula_ablation95'])\n",
    "    df_copula['descr'] = 10 #'copula'\n",
    "    df_copula95['descr'] = 11 #'copula95'\n",
    "\n",
    "    df = pd.concat([df_real95,df_excluded,\n",
    "                df_nfvae,df_nfvae95,\n",
    "                df_vae,df_vae95,\n",
    "                df_ipf,df_ipf95,\n",
    "                df_copulanf,df_copulanf95,\n",
    "                df_copula,df_copula95])\n",
    "    \n",
    "    df = (df-df.min())/(df.max()-df.min()) # all populations (for the same province) are scaled within the same metric space\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    unique_descr = df.descr.unique()\n",
    "    data_out = dict()\n",
    "    for i in range(len(keys)):\n",
    "        a = df.loc[df.descr == unique_descr[i],:].drop(columns='descr').reset_index(drop=True)\n",
    "        data_out[keys[i]] = a\n",
    "\n",
    "    return data_out\n",
    "\n",
    "\n",
    "def Distance_x1(x1,metric='euclidean'):\n",
    "    \"\"\"Function to compute the distance between all point in a set, exception made for the point at hand\"\"\"\n",
    "    # Distance matrix\n",
    "    if(metric=='euclidean'):\n",
    "        dists = pairwise_distances(x1.values, metric='euclidean') \n",
    "    elif(metric=='norm1'):\n",
    "        dists = pairwise_distances(x1.values, metric='minkowski', p=1)\n",
    "    elif(metric == 'gower'):\n",
    "        dists = gower.gower_matrix(x1)\n",
    "\n",
    "    np.fill_diagonal(dists, np.inf) \n",
    "    #del df2\n",
    "    # take the minimum distances\n",
    "    min_dists = dists.min(axis=1)\n",
    "\n",
    "    return min_dists\n",
    "\n",
    "def TableDistance(data, control_data, test_data = 'df_real95',metric='euclidean'):\n",
    "    \"\"\"Function that computes the distance between the real records to the synthetic ones, returning some statistics\"\"\"\n",
    "    \n",
    "    #df1 = data[test_data] # dataframe containing the data considered in computing the distances\n",
    "    res = pd.DataFrame(columns=['mean','std'])\n",
    "    for i in control_data:\n",
    "        # prov_res = pd.DataFrame(columns=['pop_name','min_dist'])\n",
    "        # Distance matrix\n",
    "        if(metric=='euclidean'):\n",
    "            dists = pairwise_distances(data[test_data].values,data[i].values, metric='euclidean') \n",
    "        elif(metric=='norm1'):\n",
    "            dists = pairwise_distances(data[test_data].values,data[i].values, metric='minkowski', p=1)\n",
    "        elif(metric == 'gower'):\n",
    "            dists = gower.gower_matrix(data[test_data].values,data[i].values)\n",
    "        \n",
    "        # take the minimum distances\n",
    "        min_dists = dists.min(axis=1)\n",
    "        res.loc[i,:] = [np.mean(min_dists), np.std(min_dists)]\n",
    "        \n",
    "    min_dists_benchmark = Distance_x1(data[test_data],metric=metric)\n",
    "    res.loc['Benchmark (train data -- real95)',:] = [np.mean(min_dists_benchmark), np.std(min_dists_benchmark)]#, np.std(min_dists_benchmark)/np.mean(min_dists_benchmark),\n",
    "                    #np.min(min_dists_benchmark),\n",
    "                    #np.quantile(min_dists_benchmark,0.05),np.quantile(min_dists_benchmark,0.25),np.median(min_dists_benchmark),\n",
    "                    #np.quantile(min_dists_benchmark,0.75),np.quantile(min_dists_benchmark,0.95),\n",
    "                    #np.max(min_dists_benchmark)]\n",
    "    \n",
    "    res = res.reset_index(drop=False,names='pop_name')\n",
    "    res = pd.melt(res,id_vars=[\"pop_name\"],var_name=['min_distance'],value_name='score')\n",
    "    return res #, min_dists\n",
    "\n",
    "def TableNNDR(data, control_data,test_data = 'df_real95',metric='euclidean'):\n",
    "    \"\"\"Function that compuets the ratio between the minimum and the second minimum distance between a synthetic and real record\"\"\"\n",
    "\n",
    "    res = pd.DataFrame(columns=['mean_train','std_train']) #,'mean_test','std_test'\n",
    "    for i in control_data:\n",
    "        # Distance matrix\n",
    "        if(metric=='euclidean'):\n",
    "            dists_train = pairwise_distances(data[i].values,data[test_data].values, metric='euclidean') \n",
    "            #dists_test = pairwise_distances(data[i].values,data['real_excluded'].values, metric='euclidean') \n",
    "        elif(metric=='norm1'):\n",
    "            dists_train = pairwise_distances(data[i].values,data[test_data].values, metric='minkowski', p=1)\n",
    "            #dists_test = pairwise_distances(data[i].values,data['real_excluded'].values, metric='minkowski', p=1)\n",
    "        elif(metric == 'gower'):\n",
    "            dists_train = gower.gower_matrix(data[i].values,data[test_data].values,)\n",
    "            #dists_test = gower.gower_matrix(data[i].values,data['real_excluded'].values)\n",
    "        \n",
    "        # take the minimum distances\n",
    "        sorted_rows_train = np.sort(dists_train,axis=1)\n",
    "        #sorted_rows_test = np.sort(dists_test,axis=1)\n",
    "\n",
    "        min_train = sorted_rows_train[:,0]\n",
    "        #min_test = sorted_rows_test[:,0]\n",
    "\n",
    "        second_min_train = sorted_rows_train[:,1]\n",
    "        #second_min_test = sorted_rows_test[:,1]\n",
    "\n",
    "        ratio_train = min_train/second_min_train\n",
    "        #ratio_test = min_test/second_min_test\n",
    "\n",
    "\n",
    "        #res.loc[i,:] = [np.round(np.mean(ratio_train),3), np.round(np.std(ratio_train),3), np.round(np.mean(ratio_test),3), np.round(np.std(ratio_test),3)]\n",
    "        res.loc[i,:] = [np.mean(ratio_train), np.std(ratio_train)]\n",
    "    res = res.reset_index(drop=False,names='pop_name')\n",
    "    res = pd.melt(res,id_vars=[\"pop_name\"],var_name=['distance_ratio'],value_name='score')\n",
    "        \n",
    "    return res #, ratio_train\n",
    "\n",
    "\n",
    "def min_distance_to_synth(x_real, x_synth, metric=\"euclidean\"):\n",
    "    \"\"\"This function returns the minimum distance between real and synthetic data\"\"\"\n",
    "    if(metric=='euclidean'):\n",
    "        dists = pairwise_distances(x_real, x_synth, metric=metric)\n",
    "    elif(metric=='norm1'):\n",
    "        dists = pairwise_distances(x_real, x_synth, metric='minkowski', p=1)\n",
    "    elif(metric=='gower'):\n",
    "        dists = gower.gower_matrix(x_real, x_synth)\n",
    "    \n",
    "    return dists.min(axis=1) \n",
    "\n",
    "\n",
    "def MIA_Table_Test(data,control_data,metric='euclidean',f=0.8,seed = 42):\n",
    "    \"\"\"\n",
    "    This function returns several dataframe, each dataframe reports the performance according to a measure for the classification problem.\n",
    "    The output dataframes have along the rows the synthetic populations nd along the columns the classificators.\n",
    "    \n",
    "    \"\"\"\n",
    "    res_rocauc=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_aucpr=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_precision=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_recall=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "    res_f1=pd.DataFrame(columns=['Logistic Regression','GaussianNB','KNeighbors','DecisionTree',\n",
    "                                     'Random Forest', 'SVC', 'MLP'])\n",
    "\n",
    "    for i in control_data:\n",
    "        roc_auc_list = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        f1_list = []\n",
    "        aucpr_list = []\n",
    "\n",
    "        # the features are the distances\n",
    "        train_features = min_distance_to_synth(data['df_real95'].values, data[i].values,metric=metric)#.reshape(-1,1)\n",
    "        y_train = np.array([1]*len(train_features))\n",
    "        holdout_features = min_distance_to_synth(data['df_excluded'].values, data[i].values,metric=metric)#.reshape(-1,1)\n",
    "        y_test = np.array([0]*len(holdout_features))\n",
    "\n",
    "        df_train = pd.DataFrame({'data':train_features,'label':y_train})\n",
    "        df_test = pd.DataFrame({'data':holdout_features,'label':y_test})\n",
    "\n",
    "        df_train_1 = df_train.sample(frac=f,random_state=seed)\n",
    "        df_train_2 = df_train.drop(index=df_train_1.index)\n",
    "\n",
    "        df_test_1 = df_test.sample(frac=f,random_state=seed)\n",
    "        df_test_2 = df_test.drop(index=df_test_1.index)\n",
    "\n",
    "        df_train = pd.concat([df_train_1,df_test_1]).reset_index(drop=True)\n",
    "        df_test = pd.concat([df_train_2,df_test_2]).reset_index(drop=True)\n",
    "\n",
    "        X = df_train.data.values.reshape(-1,1)\n",
    "        y = df_train.label.values\n",
    "\n",
    "        Xtest = df_test.data.values.reshape(-1,1)\n",
    "        ytest = df_test.label.values\n",
    "\n",
    "        # Logistic Regression\n",
    "        model = LogisticRegression(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # GaussianNB\n",
    "        model = GaussianNB()\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # KNeighbors\n",
    "        model = KNeighborsClassifier()\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # DecisionTree\n",
    "        model = DecisionTreeClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # Random Forest\n",
    "        model = RandomForestClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # SVC\n",
    "        model = SVC(probability=True, random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # MLP\n",
    "        model = MLPClassifier(random_state=seed)\n",
    "        model.fit(X, y)\n",
    "        y_pred_proba = model.predict_proba(Xtest)[:,1]\n",
    "        roc_auc_list.append(roc_auc_score(ytest, y_pred_proba))\n",
    "        aucpr_list.append(average_precision_score(ytest,y_pred_proba))\n",
    "        y_pred = model.predict(Xtest)\n",
    "        precision_list.append(precision_score(ytest,y_pred))\n",
    "        recall_list.append(recall_score(ytest,y_pred))\n",
    "        f1_list.append(f1_score(ytest,y_pred))\n",
    "        del model\n",
    "        del y_pred_proba\n",
    "        del y_pred\n",
    "\n",
    "        # wide output dataframe\n",
    "        res_rocauc.loc[i,:] = roc_auc_list\n",
    "        res_aucpr.loc[i,:] = aucpr_list\n",
    "        res_precision.loc[i,:] = precision_list\n",
    "        res_recall.loc[i,:] = recall_list\n",
    "        res_f1.loc[i,:] = f1_list\n",
    "\n",
    "    # long output dataframe\n",
    "    res_rocauc = res_rocauc.reset_index(drop=False,names='pop_name')\n",
    "    res_rocauc = pd.melt(res_rocauc,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_aucpr = res_aucpr.reset_index(drop=False,names='pop_name')\n",
    "    res_aucpr = pd.melt(res_aucpr,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_precision = res_precision.reset_index(drop=False,names='pop_name')\n",
    "    res_precision = pd.melt(res_precision,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_recall = res_recall.reset_index(drop=False,names='pop_name')\n",
    "    res_recall = pd.melt(res_recall,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "    res_f1 = res_f1.reset_index(drop=False,names='pop_name')\n",
    "    res_f1 = pd.melt(res_f1,id_vars=[\"pop_name\"],var_name=['classifier'],value_name='score')\n",
    "\n",
    "    return res_rocauc, res_aucpr, res_precision, res_recall, res_f1\n",
    "\n",
    "\n",
    "\n",
    "def DataPreparation_Privacy1(data):\n",
    "    \"\"\"Function to prepare the data for the privacy analyses\"\"\"\n",
    "    \n",
    "\n",
    "    for key in data.keys():\n",
    "        data[key] = ConvertBool2number(data[key])\n",
    "\n",
    "    df = pd.concat(data, ignore_index=False)\n",
    "    df = df.reset_index(level=0).rename(columns={\"level_0\": \"origine\"})\n",
    "\n",
    "    num_cols = df.select_dtypes(include=[\"number\"]).columns\n",
    "    #scaler = MinMaxScaler()\n",
    "    df[num_cols] = (df[num_cols]-df[num_cols].min())/(df[num_cols].max()-df[num_cols].min())\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    data_out = dict()\n",
    "    for i in data.keys():\n",
    "        a = df.loc[df.origine == i,:].drop(columns='origine').reset_index(drop=True)\n",
    "        data_out[i] = a\n",
    "\n",
    "    return data_out\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_austin.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_barcelona.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_brisbane.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_cape town.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_copenhagen.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_hawaii.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_hong-kong.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_lyon.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_mexico city.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_montreal.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_naples.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_paris.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_santiago.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_seattle.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_singapore.pickle',\n",
       " '/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_washington dc.pickle']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(glob(f'/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_*.pickle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forli'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ottieni il nome file senza percorso\n",
    "s='/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_forli.pickle'\n",
    "filename = s.split('/')[-1]  # \"all_baselines_austin.pickle\"\n",
    "\n",
    "# prendi la parte tra l'ultimo \"_\" e \".\"\n",
    "result = filename.split('_')[-1].split('.')[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'forli'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s='/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_forli.pickle'\n",
    "\n",
    "# prendi la parte tra l'ultimo \"_\" e \".\"\n",
    "result = s.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "euclidean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [02:01<00:00, 60.63s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#%% MAIN\n",
    "\n",
    "\n",
    "\n",
    "metrics = ['euclidean']#,'norm1'] #'euclidean',\n",
    "folder_path = '/data/housing/data/intermediate/lc_privacyStats/'\n",
    "\n",
    "for metric in metrics:\n",
    "    print(metric)\n",
    "\n",
    "    res_dist = pd.DataFrame()\n",
    "    res_ratio = pd.DataFrame()\n",
    "\n",
    "    MIA_res_auc_roc = pd.DataFrame()\n",
    "    MIA_res_auc_pr = pd.DataFrame()\n",
    "\n",
    "    for file in tqdm(sorted(glob(f'/data/housing/data/intermediate/jl_pop_synth/airbnb_baselines/all_baselines_*.pickle'))[:2]):\n",
    "        prov = file.split('/')[-1].split('_')[-1].split('.')[0]\n",
    "        # data loading\n",
    "        with open(file, 'rb') as f:\n",
    "            all_baselines = pickle.load(f)\n",
    "\n",
    "        all_baselines['df_excluded'] = all_baselines['df_real'][~all_baselines['df_real'].index.isin(all_baselines['df_real95'].index)]\n",
    "\n",
    "        del all_baselines['df_real']\n",
    "\n",
    "        # data preparation\n",
    "        data = DataPreparation_Privacy1(data=all_baselines)\n",
    "\n",
    "        control_data = [i for i in data.keys() if '95' in i and 'real' not in i]\n",
    "\n",
    "        # distances\n",
    "        dist = TableDistance(data = data, control_data=control_data, test_data = 'df_real95',metric=metric)\n",
    "        dist['city'] = prov\n",
    "\n",
    "        res_dist = pd.concat([res_dist,dist])\n",
    "\n",
    "        # ratios\n",
    "        ratio = TableNNDR(data=data, control_data=control_data,test_data = 'df_real95',metric=metric)\n",
    "        ratio['city'] = prov\n",
    "\n",
    "        res_ratio = pd.concat([res_ratio,ratio])\n",
    "\n",
    "        # MIA\n",
    "        res_auc_roc, res_auc_pr, _, _, _ = MIA_Table_Test(data,control_data,metric=metric,f=0.8,seed = 42)\n",
    "        res_auc_roc['city'] = prov\n",
    "        res_auc_pr['city'] = prov\n",
    "\n",
    "        MIA_res_auc_roc = pd.concat([MIA_res_auc_roc,res_auc_roc])\n",
    "        MIA_res_auc_pr = pd.concat([MIA_res_auc_pr,res_auc_pr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "pop_name",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "classifier",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "score",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "prov",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "a2bd2116-26be-4484-b477-2ab9f04cfec9",
       "rows": [
        [
         "0",
         "df_vae95",
         "Logistic Regression",
         "0.5577609444416713",
         "austin"
        ],
        [
         "1",
         "df_copula95",
         "Logistic Regression",
         "0.48544276943043974",
         "austin"
        ],
        [
         "2",
         "df_nf_copula95",
         "Logistic Regression",
         "0.47450456746368497",
         "austin"
        ],
        [
         "3",
         "df_shuffle_neighbourhood_num95",
         "Logistic Regression",
         "0.7297022413018519",
         "austin"
        ],
        [
         "4",
         "df_shuffle_city_num95",
         "Logistic Regression",
         "0.610717316427894",
         "austin"
        ],
        [
         "5",
         "df_shuffle_neighbourhood_bins95",
         "Logistic Regression",
         "0.6091573903059952",
         "austin"
        ],
        [
         "6",
         "df_shuffle_city_bins95",
         "Logistic Regression",
         "0.5324651824489592",
         "austin"
        ],
        [
         "7",
         "df_nfvae95",
         "Logistic Regression",
         "0.5353853641491539",
         "austin"
        ],
        [
         "8",
         "df_vae95",
         "GaussianNB",
         "0.46382843308540905",
         "austin"
        ],
        [
         "9",
         "df_copula95",
         "GaussianNB",
         "0.47672590226126893",
         "austin"
        ],
        [
         "10",
         "df_nf_copula95",
         "GaussianNB",
         "0.47383067937902457",
         "austin"
        ],
        [
         "11",
         "df_shuffle_neighbourhood_num95",
         "GaussianNB",
         "0.7297022413018519",
         "austin"
        ],
        [
         "12",
         "df_shuffle_city_num95",
         "GaussianNB",
         "0.5565629211800529",
         "austin"
        ],
        [
         "13",
         "df_shuffle_neighbourhood_bins95",
         "GaussianNB",
         "0.5765050167224081",
         "austin"
        ],
        [
         "14",
         "df_shuffle_city_bins95",
         "GaussianNB",
         "0.49029725952178904",
         "austin"
        ],
        [
         "15",
         "df_nfvae95",
         "GaussianNB",
         "0.4741052263764788",
         "austin"
        ],
        [
         "16",
         "df_vae95",
         "KNeighbors",
         "0.5080960165726551",
         "austin"
        ],
        [
         "17",
         "df_copula95",
         "KNeighbors",
         "0.47656366994459143",
         "austin"
        ],
        [
         "18",
         "df_nf_copula95",
         "KNeighbors",
         "0.4910522637647881",
         "austin"
        ],
        [
         "19",
         "df_shuffle_neighbourhood_num95",
         "KNeighbors",
         "0.5263097139719464",
         "austin"
        ],
        [
         "20",
         "df_shuffle_city_num95",
         "KNeighbors",
         "0.5158114111715669",
         "austin"
        ],
        [
         "21",
         "df_shuffle_neighbourhood_bins95",
         "KNeighbors",
         "0.5087043877601956",
         "austin"
        ],
        [
         "22",
         "df_shuffle_city_bins95",
         "KNeighbors",
         "0.507387810113313",
         "austin"
        ],
        [
         "23",
         "df_nfvae95",
         "KNeighbors",
         "0.4888621274896421",
         "austin"
        ],
        [
         "24",
         "df_vae95",
         "DecisionTree",
         "0.5107759696500773",
         "austin"
        ],
        [
         "25",
         "df_copula95",
         "DecisionTree",
         "0.4853429341586383",
         "austin"
        ],
        [
         "26",
         "df_nf_copula95",
         "DecisionTree",
         "0.502236934058803",
         "austin"
        ],
        [
         "27",
         "df_shuffle_neighbourhood_num95",
         "DecisionTree",
         "0.5130909000149753",
         "austin"
        ],
        [
         "28",
         "df_shuffle_city_num95",
         "DecisionTree",
         "0.4990890031448111",
         "austin"
        ],
        [
         "29",
         "df_shuffle_neighbourhood_bins95",
         "DecisionTree",
         "0.5271364748165527",
         "austin"
        ],
        [
         "30",
         "df_shuffle_city_bins95",
         "DecisionTree",
         "0.5048014526032047",
         "austin"
        ],
        [
         "31",
         "df_nfvae95",
         "DecisionTree",
         "0.4813308041731144",
         "austin"
        ],
        [
         "32",
         "df_vae95",
         "Random Forest",
         "0.5233739330105326",
         "austin"
        ],
        [
         "33",
         "df_copula95",
         "Random Forest",
         "0.4768288573853143",
         "austin"
        ],
        [
         "34",
         "df_nf_copula95",
         "Random Forest",
         "0.5006832476413917",
         "austin"
        ],
        [
         "35",
         "df_shuffle_neighbourhood_num95",
         "Random Forest",
         "0.5404613637498128",
         "austin"
        ],
        [
         "36",
         "df_shuffle_city_num95",
         "Random Forest",
         "0.5093907552538312",
         "austin"
        ],
        [
         "37",
         "df_shuffle_neighbourhood_bins95",
         "Random Forest",
         "0.5172403034992263",
         "austin"
        ],
        [
         "38",
         "df_shuffle_city_bins95",
         "Random Forest",
         "0.49906404432686075",
         "austin"
        ],
        [
         "39",
         "df_nfvae95",
         "Random Forest",
         "0.4770254080766735",
         "austin"
        ],
        [
         "40",
         "df_vae95",
         "SVC",
         "0.47637023910547593",
         "austin"
        ],
        [
         "41",
         "df_copula95",
         "SVC",
         "0.479870713323017",
         "austin"
        ],
        [
         "42",
         "df_nf_copula95",
         "SVC",
         "0.4740241102181401",
         "austin"
        ],
        [
         "43",
         "df_shuffle_neighbourhood_num95",
         "SVC",
         "0.37335895771976235",
         "austin"
        ],
        [
         "44",
         "df_shuffle_city_num95",
         "SVC",
         "0.6044152148954225",
         "austin"
        ],
        [
         "45",
         "df_shuffle_neighbourhood_bins95",
         "SVC",
         "0.5583100384365797",
         "austin"
        ],
        [
         "46",
         "df_shuffle_city_bins95",
         "SVC",
         "0.5201667249039086",
         "austin"
        ],
        [
         "47",
         "df_nfvae95",
         "SVC",
         "0.46292991563919533",
         "austin"
        ],
        [
         "48",
         "df_vae95",
         "MLP",
         "0.4715219887186143",
         "austin"
        ],
        [
         "49",
         "df_copula95",
         "MLP",
         "0.48544276943043974",
         "austin"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 112
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pop_name</th>\n",
       "      <th>classifier</th>\n",
       "      <th>score</th>\n",
       "      <th>prov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>df_vae95</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.557761</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>df_copula95</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.485443</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>df_nf_copula95</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.474505</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>df_shuffle_neighbourhood_num95</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.729702</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>df_shuffle_city_num95</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.610717</td>\n",
       "      <td>austin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>df_shuffle_neighbourhood_num95</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.777302</td>\n",
       "      <td>barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>df_shuffle_city_num95</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.535055</td>\n",
       "      <td>barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>df_shuffle_neighbourhood_bins95</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.639284</td>\n",
       "      <td>barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>df_shuffle_city_bins95</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.437002</td>\n",
       "      <td>barcelona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>df_nfvae95</td>\n",
       "      <td>MLP</td>\n",
       "      <td>0.476549</td>\n",
       "      <td>barcelona</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           pop_name           classifier     score       prov\n",
       "0                          df_vae95  Logistic Regression  0.557761     austin\n",
       "1                       df_copula95  Logistic Regression  0.485443     austin\n",
       "2                    df_nf_copula95  Logistic Regression  0.474505     austin\n",
       "3    df_shuffle_neighbourhood_num95  Logistic Regression  0.729702     austin\n",
       "4             df_shuffle_city_num95  Logistic Regression  0.610717     austin\n",
       "..                              ...                  ...       ...        ...\n",
       "51   df_shuffle_neighbourhood_num95                  MLP  0.777302  barcelona\n",
       "52            df_shuffle_city_num95                  MLP  0.535055  barcelona\n",
       "53  df_shuffle_neighbourhood_bins95                  MLP  0.639284  barcelona\n",
       "54           df_shuffle_city_bins95                  MLP  0.437002  barcelona\n",
       "55                       df_nfvae95                  MLP  0.476549  barcelona\n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIA_res_auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # saving\n",
    "    \n",
    "\n",
    "    res_dist.to_csv(folder_path+f'distances_{metric}_airbnb_data.csv',index=False)\n",
    "    res_ratio.to_csv(folder_path+f'ratio_{metric}_airbnb_data.csv',index=False)\n",
    "    MIA_res_auc_roc.to_csv(folder_path+f'MIA_auc_roc_{metric}_airbnb_data.csv',index=False)\n",
    "    MIA_res_auc_pr.to_csv(folder_path+f'MIA_auc_pr_{metric}_airbnb_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synpop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
